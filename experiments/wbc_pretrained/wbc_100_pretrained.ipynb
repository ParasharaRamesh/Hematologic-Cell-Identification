{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This colab notebook trains a classifier on the WBC-100 dataset using the pretrained weights from Cam16 and pRCC model\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "p9xKFFmKpyNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3TTLw_TGpyNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "id": "m6pYxgF6lTKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d111660-5181-4d14-a649-6eac02e54fa9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzipping dataset into colab instance"
      ],
      "metadata": {
        "id": "xzhVrFdh8hPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normal data\n",
        "!unzip -q '/content/drive/MyDrive/WBC_100.zip' -d '/content/'\n",
        "\n",
        "#On Balanced data\n",
        "# !unzip -q '/content/drive/MyDrive/WBC_100_balanced.zip' -d '/content/'\n",
        "\n",
        "# Test data\n",
        "!unzip -q '/content/drive/MyDrive/WBC_test.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "cSVm-ZBm8amL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing things"
      ],
      "metadata": {
        "id": "KdsDcRTsvkUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split, Subset, TensorDataset\n",
        "import os\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch import nn, optim\n",
        "from tqdm.auto import tqdm\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "8ZDhkS77vNPR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters\n"
      ],
      "metadata": {
        "id": "8GwRwKCtvnDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    drive_path = \"/content/drive/MyDrive\"\n",
        "    datasets_path = f\"/content/WBC_100\"\n",
        "    # Balanced\n",
        "    # datasets_path = f\"/content/WBC_100_balanced\"\n",
        "    eval_path = f\"/content/WBC_test\"\n",
        "\n",
        "    weights_path = f\"{drive_path}/weights\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    test_split = 0.2\n",
        "    validation_split = 0.3\n",
        "\n",
        "    learning_rate = 0.01\n",
        "    weight_decay = 1e-4\n",
        "    grad_clip = 0.1\n",
        "\n",
        "    pRCC_batch_size = 16\n",
        "    pRCC_img_resize_target = 512  # from 2000 -> 512 ( Too big to fit on machine!)\n",
        "    pRCC_latent_dim = 2048\n",
        "\n",
        "    cam_batch_size = 16\n",
        "    # cam_img_resize_target = 256 # from 384 -> 256\n",
        "    cam_img_resize_target = 224 # as we are passing it into resnet\n",
        "\n",
        "    wbc_batch_size = 16\n",
        "    wbc_img_resize_target = 256 # from 575 -> 256\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "_yNNJZw6xcGc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Util functions\n"
      ],
      "metadata": {
        "id": "8ijxf5Y5wCLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions for plotting graphs\n",
        "def plot_model_stats(experiment, epochs, training_losses, validation_losses, training_accuracy, validation_accuracy):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "    # Plot data on each subplot and add labels\n",
        "    axes[0, 0].plot(epochs, training_losses, marker=\"o\", color=\"red\")\n",
        "    axes[0, 0].set_title(f'{experiment}: Training Loss vs Epochs')\n",
        "    axes[0, 0].set_xlabel('Epochs')\n",
        "    axes[0, 0].set_ylabel('Training Loss')\n",
        "\n",
        "    axes[0, 1].plot(epochs, training_accuracy, marker=\"o\", color=\"green\")\n",
        "    axes[0, 1].set_title(f'{experiment}: Training Accuracy vs Epochs')\n",
        "    axes[0, 1].set_xlabel('Epochs')\n",
        "    axes[0, 1].set_ylabel('Training Accuracy')\n",
        "\n",
        "    axes[1, 0].plot(epochs, validation_losses, marker=\"o\", color=\"red\")\n",
        "    axes[1, 0].set_title(f'{experiment}: Validation Loss vs Epochs')\n",
        "    axes[1, 0].set_xlabel('Epochs')\n",
        "    axes[1, 0].set_ylabel('Validation Loss')\n",
        "\n",
        "    axes[1, 1].plot(epochs, validation_accuracy, marker=\"o\", color=\"green\")\n",
        "    axes[1, 1].set_title(f'{experiment}: Validation Accuracy vs Epochs')\n",
        "    axes[1, 1].set_xlabel('Epochs')\n",
        "    axes[1, 1].set_ylabel('Validation Accuracy')\n",
        "\n",
        "    # Add space between subplots\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "    # close it properly\n",
        "    plt.clf()\n",
        "    plt.cla()\n",
        "    plt.close()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "    # close it properly\n",
        "    plt.clf()\n",
        "    plt.cla()\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "dFodqgL2wErT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions needed for debugging dataset related issues"
      ],
      "metadata": {
        "collapsed": false,
        "id": "TcU5X3wupyNs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "outputs": [],
      "source": [
        "class LocalDebug:\n",
        "    @staticmethod\n",
        "    def create_mini_dataset(dataset, num_samples):\n",
        "        '''\n",
        "        Function to be used locally for checking if the model runs or not!\n",
        "\n",
        "        :param dataset:\n",
        "        :param num_samples:\n",
        "        :return:\n",
        "        '''\n",
        "        subset_indices = torch.randperm(len(dataset))[:num_samples]\n",
        "        subset_dataset = Subset(dataset, subset_indices)\n",
        "        return subset_dataset\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_mean_and_std_of_dataset(dataset):\n",
        "        '''\n",
        "        Useful when determining what transforms to set\n",
        "\n",
        "        :param dataset:\n",
        "        :return:\n",
        "        '''\n",
        "        # dataset =  ImageFolder(root=self.path, transform=transforms.ToTensor())\n",
        "\n",
        "        # Initialize variables to accumulate mean and standard deviation\n",
        "        mean = torch.zeros(3)\n",
        "        std = torch.zeros(3)\n",
        "\n",
        "        # Loop through the dataset to compute mean and standard deviation\n",
        "        for img, _ in dataset:\n",
        "            mean += img.mean(1).mean(1)\n",
        "            std += img.view(3, -1).std(1)\n",
        "\n",
        "        # Calculate the mean and standard deviation\n",
        "        mean /= len(dataset)\n",
        "        std /= len(dataset)\n",
        "\n",
        "        return (tuple(mean.tolist()), tuple(std.tolist()))"
      ],
      "metadata": {
        "id": "Oh8kRLdppyNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset wrapper to move tensors to device"
      ],
      "metadata": {
        "collapsed": false,
        "id": "i1-e3NRSpyNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Wrapper on top of dataloader to move tensors to device\n",
        "'''\n",
        "class DeviceDataLoader(DataLoader):\n",
        "    def __init__(self, dataset, batch_size, shuffle=True, device=config.device):\n",
        "        super().__init__(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle\n",
        "        )\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in super().__iter__():\n",
        "            yield self._move_to_device(batch)\n",
        "\n",
        "    def _move_to_device(self, batch):\n",
        "        if isinstance(batch, torch.Tensor):\n",
        "            return batch.to(self.device)\n",
        "        elif isinstance(batch, (list, tuple)):\n",
        "            return [self._move_to_device(item) for item in batch]\n",
        "        elif isinstance(batch, dict):\n",
        "            return {key: self._move_to_device(value) for key, value in batch.items()}\n",
        "        else:\n",
        "            return batch\n",
        "\n"
      ],
      "metadata": {
        "id": "KjAg8ST3xSk4"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n"
      ],
      "metadata": {
        "id": "Mg3Gkjryvq1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Custom dataset for yielding the data as per different model input sizes\n",
        "'''\n",
        "class MedicalDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 dataset,\n",
        "                 wbc_resize_to=config.wbc_img_resize_target,\n",
        "                 cam_resize_to=config.cam_img_resize_target,\n",
        "                 pRCC_resize_to=config.pRCC_img_resize_target\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        # image resize sizes\n",
        "        self.cam_resize_to = cam_resize_to\n",
        "        self.pRCC_resize_to = pRCC_resize_to\n",
        "        self.wbc_resize_to = wbc_resize_to\n",
        "\n",
        "        # transformations\n",
        "        self.wbc_resize_transform = transforms.Compose([\n",
        "            transforms.Resize((self.wbc_resize_to, self.wbc_resize_to)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.cam_resize_transform = self.resize_transformations(self.cam_resize_to)\n",
        "        self.pRCC_resize_transform = self.resize_transformations(self.pRCC_resize_to)\n",
        "\n",
        "    def resize_transformations(self, resize_to):\n",
        "        return transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((resize_to, resize_to)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.dataset[idx]\n",
        "        wbc_img_tensor, target_tensor = data\n",
        "        wbc_img_tensor = wbc_img_tensor.squeeze()\n",
        "        pRCC_img_tensor = self.pRCC_resize_transform(wbc_img_tensor)\n",
        "        cam_img_tensor = self.cam_resize_transform(wbc_img_tensor)\n",
        "        return pRCC_img_tensor, cam_img_tensor, wbc_img_tensor, target_tensor"
      ],
      "metadata": {
        "id": "wwpxf7XstLke"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PretrainedWBCDataset:\n",
        "    def __init__(self,\n",
        "                 train_path,\n",
        "                 eval_path,\n",
        "                 eval_size=200,\n",
        "                 val_split=config.validation_split,\n",
        "                 batch_size=config.wbc_batch_size,\n",
        "                 wbc_resize_to=config.wbc_img_resize_target,\n",
        "                 take_subset=False\n",
        "             ):\n",
        "        # constants\n",
        "        self.train_path = train_path\n",
        "        self.eval_path = eval_path\n",
        "        self.batch_size = batch_size\n",
        "        self.val_split = val_split\n",
        "        self.eval_size = eval_size\n",
        "        self.take_subset = take_subset\n",
        "\n",
        "        # paths\n",
        "        self.train_path = os.path.join(self.train_path, \"train\", \"data\")\n",
        "        self.eval_path = os.path.join(self.eval_path, \"val\", \"data\")\n",
        "\n",
        "        self.wbc_resize_to = wbc_resize_to\n",
        "\n",
        "        # transformations\n",
        "        self.wbc_resize_transform = transforms.Compose([\n",
        "            transforms.Resize((self.wbc_resize_to, self.wbc_resize_to)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        # create dataset\n",
        "        self.test_dataset, self.validation_dataset = self.get_test_val_datasets()\n",
        "        self.train_dataset = self.get_train_dataset()\n",
        "        print(\"Datasets are initialized\")\n",
        "\n",
        "    def get_train_dataset(self):\n",
        "        unbalanced_dataset = ImageFolder(root=self.train_path, transform=self.wbc_resize_transform)\n",
        "        print(\"constructing train dataset\")\n",
        "        return MedicalDataset(unbalanced_dataset)\n",
        "\n",
        "    def get_test_val_datasets(self):\n",
        "        image_folder = ImageFolder(root=self.eval_path, transform=self.wbc_resize_transform)\n",
        "        # Calculate the number of samples to use for validation\n",
        "\n",
        "        num_total_samples = len(image_folder)\n",
        "\n",
        "        # find the no of train samples\n",
        "        num_validation_samples = int(num_total_samples * self.val_split)\n",
        "        num_test_samples = num_total_samples - num_validation_samples\n",
        "\n",
        "        test_dataset, validation_dataset = random_split(image_folder, [num_test_samples, num_validation_samples])\n",
        "\n",
        "        if self.take_subset:\n",
        "            # find the no of train samples\n",
        "            num_val_eval_samples = int(self.eval_size * self.val_split)\n",
        "            num_test_eval_samples = self.eval_size - num_val_eval_samples\n",
        "\n",
        "            test_dataset = LocalDebug.create_mini_dataset(test_dataset, num_test_eval_samples)\n",
        "            validation_dataset = LocalDebug.create_mini_dataset(validation_dataset, num_val_eval_samples)\n",
        "\n",
        "        print(\"constructing test & val dataset with augmentation\")\n",
        "        return MedicalDataset(test_dataset), MedicalDataset(validation_dataset)\n",
        "\n",
        "    def get_dataloaders(self):\n",
        "        '''\n",
        "\n",
        "        :return: the Train, Val and test dataloaders\n",
        "        '''\n",
        "\n",
        "        # Create DataLoaders for validation and test sets\n",
        "        return DeviceDataLoader(self.train_dataset, self.batch_size), \\\n",
        "            DeviceDataLoader(self.test_dataset, self.batch_size), \\\n",
        "            DeviceDataLoader(self.validation_dataset, self.batch_size)"
      ],
      "metadata": {
        "id": "tSY6x-TwvtHe"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generic Trainer\n"
      ],
      "metadata": {
        "id": "hrIB2bguvtg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, name, dataset, model, save_dir, device=config.device):\n",
        "        '''\n",
        "\n",
        "        :param name: name of the experiement\n",
        "        :param dataset: the dataset object which implements the method get_dataloaders()\n",
        "        :param model: the model architecture used\n",
        "        :param loss_criterion: the loss function used\n",
        "        :param save_dir: path where the model weights can be saved\n",
        "        '''\n",
        "        self.name = name\n",
        "        self.dataset = dataset\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        # create the directory if it doesnt exist!\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.join(self.save_dir, self.name), exist_ok=True)\n",
        "\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.batch_size = self.dataset.batch_size\n",
        "\n",
        "        # get loaders (each of which already moves tensors to device)\n",
        "        self.train_loader, self.test_loader, self.val_loader = self.dataset.get_dataloaders()\n",
        "\n",
        "        # Adam optimizer\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "\n",
        "    # find the most recent file and return the path\n",
        "    def get_model_checkpoint_path(self, epoch_num=None):\n",
        "        directory = os.path.join(self.save_dir, self.name)\n",
        "        if epoch_num == None:\n",
        "            # Get a list of all files in the directory\n",
        "            files = os.listdir(directory)\n",
        "\n",
        "            # Filter out only the files (exclude directories)\n",
        "            files = [f for f in files if os.path.isfile(os.path.join(directory, f))]\n",
        "\n",
        "            # Sort the files by their modification time in descending order (most recent first)\n",
        "            files.sort(key=lambda x: os.path.getmtime(os.path.join(directory, x)), reverse=True)\n",
        "\n",
        "            # Get the name of the most recently added file\n",
        "            model_file = files[0] if files else None\n",
        "        else:\n",
        "            model_file = f\"model_epoch_{epoch_num}.pt\"\n",
        "        return os.path.join(directory, model_file)\n",
        "\n",
        "    # main train code\n",
        "    def train(self,\n",
        "              num_epochs,\n",
        "              resume_epoch_num=None,\n",
        "              load_from_checkpoint=False,\n",
        "              epoch_saver_count=2):\n",
        "        '''\n",
        "\n",
        "        :param num_epochs:\n",
        "        :param resume_epoch_num: just the name of the model checkpoint\n",
        "        :param load_from_checkpoint: boolean indicating if we need to load from checkpoint or not\n",
        "        :param epoch_saver_count:\n",
        "        :return:\n",
        "        '''\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # initialize the params from the saved checkpoint\n",
        "        self.init_params_from_checkpoint_hook(load_from_checkpoint, resume_epoch_num)\n",
        "\n",
        "        # set up scheduler\n",
        "        self.init_scheduler_hook(num_epochs)\n",
        "\n",
        "        # Custom progress bar for total epochs with color and displaying average epoch loss\n",
        "        total_progress_bar = tqdm(\n",
        "            total=num_epochs, desc=f\"Total Epochs\", position=0,\n",
        "            bar_format=\"{desc}: {percentage}% |{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\",\n",
        "            dynamic_ncols=True, ncols=100, colour='red'\n",
        "        )\n",
        "\n",
        "        # Train loop\n",
        "        for epoch in range(self.start_epoch, self.start_epoch + num_epochs):\n",
        "            # Custom progress bar for each epoch with color\n",
        "            epoch_progress_bar = tqdm(\n",
        "                total=len(self.train_loader),\n",
        "                desc=f\"Epoch {epoch + 1}/{self.start_epoch + num_epochs}\",\n",
        "                position=1,\n",
        "                leave=False,\n",
        "                dynamic_ncols=True,\n",
        "                ncols=100,\n",
        "                colour='green'\n",
        "            )\n",
        "\n",
        "            # set model to train mode\n",
        "            self.model.train()\n",
        "\n",
        "            # set the epoch training loss\n",
        "            epoch_training_loss = 0.0\n",
        "\n",
        "            # iterate over each batch\n",
        "            for batch_idx, data in enumerate(self.train_loader):\n",
        "                loss = self.calculate_loss_hook(data)\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping\n",
        "                nn.utils.clip_grad_value_(self.model.parameters(), config.grad_clip)\n",
        "\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # scheduler update\n",
        "                if self.scheduler:\n",
        "                    self.scheduler.step()\n",
        "\n",
        "                # add to epoch loss\n",
        "                epoch_training_loss += loss.item()\n",
        "\n",
        "                # Update the epoch progress bar (overwrite in place)\n",
        "                postfix = {\n",
        "                    \"loss\": loss.item()\n",
        "                }\n",
        "\n",
        "                # e.g. computes things like accuracy\n",
        "                batch_stats = self.calculate_train_batch_stats_hook()\n",
        "\n",
        "                postfix.update(batch_stats)\n",
        "\n",
        "                epoch_progress_bar.set_postfix(postfix)\n",
        "                epoch_progress_bar.update(1)\n",
        "\n",
        "            # close the epoch progress bar\n",
        "            epoch_progress_bar.close()\n",
        "\n",
        "            # calculate average epoch train statistics\n",
        "            avg_train_stats = self.calculate_avg_train_stats_hook(epoch_training_loss)\n",
        "\n",
        "            # calculate validation statistics\n",
        "            avg_val_stats = self.validation_hook()\n",
        "\n",
        "            # Store running history\n",
        "            self.store_running_history_hook(epoch, avg_train_stats, avg_val_stats)\n",
        "\n",
        "            # Show epoch stats (NOTE: Can clear the batch stats here)\n",
        "            print(f\"# Epoch {epoch+1}\")\n",
        "            epoch_postfix = self.calculate_and_print_epoch_stats_hook(avg_train_stats, avg_val_stats)\n",
        "\n",
        "\n",
        "            # Update the total progress bar\n",
        "            total_progress_bar.set_postfix(epoch_postfix)\n",
        "\n",
        "            # Close tqdm bar\n",
        "            total_progress_bar.update(1)\n",
        "\n",
        "            # Save model checkpoint periodically\n",
        "            need_to_save_model_checkpoint = (epoch + 1) % epoch_saver_count == 0\n",
        "            if need_to_save_model_checkpoint:\n",
        "                print(f\"Going to save model {self.name} @ Epoch:{epoch + 1}\")\n",
        "                self.save_model_checkpoint_hook(epoch, avg_train_stats, avg_val_stats)\n",
        "\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        # Close the total progress bar\n",
        "        total_progress_bar.close()\n",
        "\n",
        "        # Return the current state\n",
        "        return self.get_current_running_history_state_hook()\n",
        "\n",
        "    # hooks\n",
        "    def init_params_from_checkpoint_hook(self, load_from_checkpoint, resume_checkpoint):\n",
        "        raise NotImplementedError(\"Need to implement hook for initializing params from checkpoint\")\n",
        "\n",
        "    def init_scheduler_hook(self, num_epochs):\n",
        "        # optimizer is already defined in the super class constructor at this point\n",
        "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            self.optimizer,\n",
        "            config.learning_rate,\n",
        "            epochs=num_epochs,\n",
        "            steps_per_epoch=len(self.train_loader)\n",
        "        )\n",
        "    def calculate_loss_hook(self, data):\n",
        "        raise NotImplementedError(\"Need to implement hook for computing the custom loss value\")\n",
        "\n",
        "    def calculate_train_batch_stats_hook(self):\n",
        "        raise NotImplementedError(\"Need to implement this hook for computing the batch statistics like accuracy\")\n",
        "\n",
        "    def calculate_avg_train_stats_hook(self):\n",
        "        raise NotImplementedError(\n",
        "            \"Need to implement this hook for calculating train loss and train accuracy if applicable\")\n",
        "\n",
        "    def validation_hook(self):\n",
        "        raise NotImplementedError(\"Need to implement this hook to calculate the validation stats\")\n",
        "\n",
        "    def calculate_and_print_epoch_stats_hook(self):\n",
        "        raise NotImplementedError(\n",
        "            \"Need to implement this hook to calculate and print the epoch statistics and return the postfix dictinoary\")\n",
        "\n",
        "    def store_running_history_hook(self, epoch, avg_train_stats, avg_val_stats):\n",
        "        raise NotImplementedError(\"Need to implement this hook to store the running history of stats for each epoch\")\n",
        "\n",
        "    def save_model_checkpoint_hook(self, epoch, avg_train_stats, avg_val_stats):\n",
        "        raise NotImplementedError(\"Need to implement this hook to save the model checkpoints\")\n",
        "\n",
        "    def get_current_running_history_state_hook(self):\n",
        "        raise NotImplementedError(\"Need to implement this hook to return the history after training the model\")\n"
      ],
      "metadata": {
        "id": "dVPanvWOv37b"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subclassing the Generic Trainer for classification tasks"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c4aAxtnipyNu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [],
      "source": [
        "class ClassificationTrainer(Trainer):\n",
        "    def __init__(self, name, dataset, model, save_dir, num_classes):\n",
        "        super().__init__(name, dataset, model, save_dir)\n",
        "\n",
        "        # structured similarity index\n",
        "        self.loss_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Values which can change based on loaded checkpoint\n",
        "        self.start_epoch = 0\n",
        "        self.epoch_numbers = []\n",
        "        self.training_losses = []\n",
        "        self.training_accuracies = []\n",
        "        self.validation_losses = []\n",
        "        self.validation_accuracies = []\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.train_correct_predictions = 0\n",
        "        self.train_total_batches = 0\n",
        "\n",
        "    # hooks\n",
        "    def init_params_from_checkpoint_hook(self, load_from_checkpoint, resume_epoch_num):\n",
        "        if load_from_checkpoint:\n",
        "            # NOTE: resume_epoch_num can be None here if we want to load from the most recently saved checkpoint!\n",
        "            checkpoint_path = self.get_model_checkpoint_path(resume_epoch_num)\n",
        "            checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "            # load previous state\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "            # Things we are keeping track of\n",
        "            self.start_epoch = checkpoint['epoch']\n",
        "            self.epoch_numbers = checkpoint['epoch_numbers']\n",
        "            self.training_losses = checkpoint['training_losses']\n",
        "            self.validation_losses = checkpoint['validation_losses']\n",
        "            self.training_accuracies = checkpoint['training_accuracies']\n",
        "            self.validation_accuracies = checkpoint['validation_accuracies']\n",
        "\n",
        "            print(f\"Model checkpoint for {self.name} is loaded from {checkpoint_path}!\")\n",
        "\n",
        "    def calculate_train_batch_stats_hook(self):\n",
        "        # Note: No accuracy to compute so leaving it as is.\n",
        "        batch_stats = {\n",
        "            \"batch_acc\": self.batch_accuracy\n",
        "        }\n",
        "        self.batch_accuracy = 0\n",
        "        return batch_stats\n",
        "\n",
        "    def calculate_avg_train_stats_hook(self, epoch_training_loss):\n",
        "        # NOTE: no need to calculate avg training accuracy here\n",
        "        avg_training_loss_for_epoch = epoch_training_loss / len(self.train_loader)\n",
        "        avg_training_accuracy = self.train_correct_predictions / self.train_total_batches\n",
        "\n",
        "        epoch_train_stats = {\n",
        "            \"avg_training_loss\": avg_training_loss_for_epoch,\n",
        "            \"avg_training_accuracy\": avg_training_accuracy\n",
        "        }\n",
        "\n",
        "        # reset\n",
        "        self.train_correct_predictions = 0\n",
        "        self.train_total_batches = 0\n",
        "\n",
        "        return epoch_train_stats\n",
        "\n",
        "    def store_running_history_hook(self, epoch, avg_train_stats, avg_val_stats):\n",
        "        self.epoch_numbers.append(epoch + 1)\n",
        "        self.training_losses.append(avg_train_stats[\"avg_training_loss\"])\n",
        "        self.training_accuracies.append(avg_train_stats[\"avg_training_accuracy\"])\n",
        "\n",
        "        self.validation_losses.append(avg_val_stats[\"avg_val_loss_for_epoch\"])\n",
        "        self.validation_accuracies.append(avg_val_stats[\"avg_val_accuracy\"])\n",
        "\n",
        "    def calculate_and_print_epoch_stats_hook(self, avg_train_stats, avg_val_stats):\n",
        "        print(\n",
        "            f\"Epoch loss: {avg_train_stats['avg_training_loss']} | Train Acc: {avg_train_stats['avg_training_accuracy']} | Val Acc: {avg_val_stats['avg_val_accuracy']} | Val loss: {avg_val_stats['avg_val_loss_for_epoch']}\")\n",
        "\n",
        "        return {\n",
        "            \"epoch_loss\": avg_train_stats['avg_training_loss'],\n",
        "            \"val_loss\": avg_val_stats['avg_val_loss_for_epoch'],\n",
        "            \"train_acc\": avg_train_stats['avg_training_accuracy'],\n",
        "            \"val_acc\": avg_val_stats['avg_val_accuracy']\n",
        "        }\n",
        "\n",
        "    def save_model_checkpoint_hook(self, epoch, avg_train_stats, avg_val_stats):\n",
        "        # set it to train mode to save the weights (but doesn't matter apparently!)\n",
        "        self.model.train()\n",
        "\n",
        "        # create the directory if it doesn't exist\n",
        "        model_save_directory = os.path.join(self.save_dir, self.name)\n",
        "        os.makedirs(model_save_directory, exist_ok=True)\n",
        "\n",
        "        # Checkpoint the model at the end of each epoch\n",
        "        checkpoint_path = os.path.join(model_save_directory, f'model_epoch_{epoch + 1}.pt')\n",
        "        torch.save(\n",
        "            {\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                'epoch': epoch + 1,\n",
        "                'epoch_numbers': self.epoch_numbers,\n",
        "                'training_losses': self.training_losses,\n",
        "                'training_accuracies': self.training_accuracies,\n",
        "                'validation_losses': self.validation_losses,\n",
        "                'validation_accuracies': self.validation_accuracies\n",
        "            },\n",
        "            checkpoint_path\n",
        "        )\n",
        "        print(f\"Saved the model checkpoint for experiment {self.name} for epoch {epoch + 1}\")\n",
        "\n",
        "    def get_current_running_history_state_hook(self):\n",
        "        return self.epoch_numbers, self.training_losses, self.training_accuracies, self.validation_losses, self.validation_accuracies\n",
        "\n",
        "    # util code\n",
        "    def one_hot(self, labels):\n",
        "        # Create an empty one-hot tensor\n",
        "        one_hot_tensor = torch.zeros((labels.size(0), self.num_classes), dtype=torch.float32).to(config.device)\n",
        "\n",
        "        # Use scatter to fill in the one-hot tensor\n",
        "        one_hot_tensor.scatter_(1, labels.view(-1, 1), 1)\n",
        "\n",
        "        return one_hot_tensor"
      ],
      "metadata": {
        "id": "BDzfI6Q2pyNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WBC Trainer"
      ],
      "metadata": {
        "id": "FQnbR28zv4ZD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "outputs": [],
      "source": [
        "class WBCClassifierTrainer(ClassificationTrainer):\n",
        "    def __init__(self, name, dataset, model, save_dir, num_classes=5):\n",
        "        super().__init__(name, dataset, model, save_dir, num_classes)\n",
        "        # Class labels\n",
        "        self.class_labels = {'Basophil': 0, 'Eosinophil': 1, 'Lymphocyte': 2, 'Monocyte': 3, 'Neutrophil': 4}\n",
        "        # Prettify class labels\n",
        "        self.class_names = list(self.class_labels.keys())\n",
        "\n",
        "    # hooks\n",
        "    def calculate_loss_hook(self, data):\n",
        "        images, labels = data\n",
        "        one_hot_labels = self.one_hot(labels)\n",
        "        output_logits = self.model(images)\n",
        "        loss = self.loss_criterion(output_logits, one_hot_labels)\n",
        "\n",
        "        # compute the batch stats right here and save it\n",
        "        output_probs = nn.Softmax(dim=1)(output_logits)\n",
        "        predicted = torch.argmax(output_probs, 1)\n",
        "        batch_correct_predictions = (predicted == labels).sum().item()\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        # store the accuracies\n",
        "        self.batch_accuracy = batch_correct_predictions / batch_size\n",
        "        self.train_correct_predictions += batch_correct_predictions\n",
        "        self.train_total_batches += labels.size(0)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_hook(self):\n",
        "        '''\n",
        "        :return: avg val loss for that epoch\n",
        "        '''\n",
        "        val_loss = 0.0\n",
        "        val_correct_predictions = 0\n",
        "        total_val_samples = 0\n",
        "\n",
        "        # set to eval mode\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for val_batch_idx, val_data in enumerate(self.val_loader):\n",
        "                val_images, val_labels = val_data\n",
        "                one_hot_val_labels = self.one_hot(val_labels)\n",
        "\n",
        "                val_logits = self.model(val_images)\n",
        "\n",
        "                val_loss += self.loss_criterion(val_logits, one_hot_val_labels).item()\n",
        "\n",
        "                # Compute validation accuracy for this batch\n",
        "                val_probs = nn.Softmax(dim=1)(val_logits)\n",
        "                val_predicted = torch.argmax(val_probs, dim=1)\n",
        "                total_val_samples += val_labels.size(0)\n",
        "                val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "        # Calculate average validation loss for the epoch\n",
        "        avg_val_loss_for_epoch = val_loss / len(self.val_loader)\n",
        "\n",
        "        # Calculate validation accuracy for the epoch\n",
        "        avg_val_accuracy = val_correct_predictions / total_val_samples\n",
        "\n",
        "        return {\n",
        "            \"avg_val_loss_for_epoch\": avg_val_loss_for_epoch,\n",
        "            \"avg_val_accuracy\": avg_val_accuracy\n",
        "        }\n",
        "\n",
        "    def test_model(self):\n",
        "        test_loss = 0.0\n",
        "        test_correct_predictions = 0\n",
        "        total_test_samples = 0\n",
        "\n",
        "        # Initialize lists to store true labels and predicted labels\n",
        "        true_labels = []\n",
        "        predicted_labels = []\n",
        "\n",
        "        # set to eval mode\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for test_batch_idx, test_data in enumerate(self.test_loader):\n",
        "                test_images, test_labels = test_data\n",
        "                one_hot_test_labels = self.one_hot(test_labels)\n",
        "\n",
        "                test_logits = self.model(test_images)\n",
        "\n",
        "                test_loss += self.loss_criterion(test_logits, one_hot_test_labels).item()\n",
        "\n",
        "                # Compute validation accuracy for this batch\n",
        "                test_probs = nn.Softmax(dim=1)(test_logits)\n",
        "                test_predicted = torch.argmax(test_probs, dim=1)\n",
        "                total_test_samples += test_labels.size(0)\n",
        "                test_correct_predictions += (test_predicted == test_labels).sum().item()\n",
        "\n",
        "                # Append true and predicted labels for each batch\n",
        "                true_labels.extend(test_labels.cpu().numpy())\n",
        "                predicted_labels.extend(test_predicted.cpu().numpy())\n",
        "\n",
        "        # Calculate average validation loss for the epoch\n",
        "        avg_test_loss = test_loss / len(self.test_loader)\n",
        "\n",
        "        # Calculate validation accuracy for the epoch\n",
        "        avg_test_accuracy = test_correct_predictions / total_test_samples\n",
        "\n",
        "        conf_matrix, prettified_f1_scores, prettified_precision_scores, prettified_recall_scores = self.get_metrics_for_class_predictions(\n",
        "            predicted_labels, true_labels\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"test_loss\": avg_test_loss,\n",
        "            \"test_accuracy\": avg_test_accuracy,\n",
        "            \"conf_matrix\": conf_matrix,\n",
        "            \"f1_scores\": prettified_f1_scores,\n",
        "            \"recall_scores\": prettified_recall_scores,\n",
        "            \"precision_scores\": prettified_precision_scores\n",
        "        }\n",
        "    def get_metrics_for_class_predictions(self, predicted_labels, true_labels):\n",
        "        # Calculate the confusion matrix\n",
        "        conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "        # Calculate F1 score, recall, and precision for each class\n",
        "        f1_scores = f1_score(true_labels, predicted_labels, average=None)\n",
        "        recall_scores = recall_score(true_labels, predicted_labels, average=None)\n",
        "        precision_scores = precision_score(true_labels, predicted_labels, average=None)\n",
        "        # Create dictionaries with prettified class labels\n",
        "        prettified_f1_scores = {self.class_names[i]: f1_scores[i] for i in range(len(self.class_names))}\n",
        "        prettified_recall_scores = {self.class_names[i]: recall_scores[i] for i in range(len(self.class_names))}\n",
        "        prettified_precision_scores = {self.class_names[i]: precision_scores[i] for i in range(len(self.class_names))}\n",
        "        # Print the confusion matrix with class labels\n",
        "        self.print_confusion_matrix(conf_matrix)\n",
        "        return conf_matrix, prettified_f1_scores, prettified_precision_scores, prettified_recall_scores\n",
        "\n",
        "    def print_confusion_matrix(self, conf_matrix):\n",
        "        print(\"Confusion Matrix\")\n",
        "        cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=self.class_names)\n",
        "        cm_display.plot()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "yRmGOuq4cCf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer for the Pretrained WBC Classifier"
      ],
      "metadata": {
        "id": "zY_9d6jdcRh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PretrainedWBCClassifierTrainer(WBCClassifierTrainer):\n",
        "    def __init__(self, name, dataset, model, save_dir, num_classes=5):\n",
        "        super().__init__(name, dataset, model, save_dir, num_classes)\n",
        "\n",
        "        # Class labels\n",
        "        self.class_labels = {'Basophil': 0, 'Eosinophil': 1, 'Lymphocyte': 2, 'Monocyte': 3, 'Neutrophil': 4}\n",
        "        # Prettify class labels\n",
        "        self.class_names = list(self.class_labels.keys())\n",
        "\n",
        "    # hooks\n",
        "    def calculate_loss_hook(self, data):\n",
        "        pRCC_imgs, cam_imgs, wbc_imgs, labels = data\n",
        "        one_hot_labels = self.one_hot(labels)\n",
        "\n",
        "        output_logits = self.model(pRCC_imgs, cam_imgs, wbc_imgs)\n",
        "\n",
        "        loss = self.loss_criterion(output_logits, one_hot_labels)\n",
        "\n",
        "        # compute the batch stats right here and save it\n",
        "        output_probs = nn.Softmax(dim=1)(output_logits)\n",
        "        predicted = torch.argmax(output_probs, 1)\n",
        "        batch_correct_predictions = (predicted == labels).sum().item()\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        # store the accuracies\n",
        "        self.batch_accuracy = batch_correct_predictions / batch_size\n",
        "        self.train_correct_predictions += batch_correct_predictions\n",
        "        self.train_total_batches += labels.size(0)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_hook(self):\n",
        "        '''\n",
        "        :return: avg val loss for that epoch\n",
        "        '''\n",
        "        val_loss = 0.0\n",
        "        val_correct_predictions = 0\n",
        "        total_val_samples = 0\n",
        "\n",
        "        # set to eval mode\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for val_batch_idx, val_data in enumerate(self.val_loader):\n",
        "                val_pRCC_imgs, val_cam_imgs, val_wbc_imgs, val_labels = val_data\n",
        "                one_hot_val_labels = self.one_hot(val_labels)\n",
        "\n",
        "                val_logits = self.model(val_pRCC_imgs, val_cam_imgs, val_wbc_imgs)\n",
        "\n",
        "                val_loss += self.loss_criterion(val_logits, one_hot_val_labels).item()\n",
        "\n",
        "                # Compute validation accuracy for this batch\n",
        "                val_probs = nn.Softmax(dim=1)(val_logits)\n",
        "                val_predicted = torch.argmax(val_probs, dim=1)\n",
        "                total_val_samples += val_labels.size(0)\n",
        "                val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "        # Calculate average validation loss for the epoch\n",
        "        avg_val_loss_for_epoch = val_loss / len(self.val_loader)\n",
        "\n",
        "        # Calculate validation accuracy for the epoch\n",
        "        avg_val_accuracy = val_correct_predictions / total_val_samples\n",
        "\n",
        "        return {\n",
        "            \"avg_val_loss_for_epoch\": avg_val_loss_for_epoch,\n",
        "            \"avg_val_accuracy\": avg_val_accuracy\n",
        "        }\n",
        "\n",
        "    def test_model(self):\n",
        "        test_loss = 0.0\n",
        "        test_correct_predictions = 0\n",
        "        total_test_samples = 0\n",
        "\n",
        "        # Initialize lists to store true labels and predicted labels\n",
        "        true_labels = []\n",
        "        predicted_labels = []\n",
        "\n",
        "        # set to eval mode\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for test_batch_idx, test_data in enumerate(self.test_loader):\n",
        "                test_pRCC_imgs, test_cam_imgs, test_wbc_imgs, test_labels = test_data\n",
        "                one_hot_test_labels = self.one_hot(test_labels)\n",
        "\n",
        "                test_logits = self.model(test_pRCC_imgs, test_cam_imgs, test_wbc_imgs)\n",
        "\n",
        "                test_loss += self.loss_criterion(test_logits, one_hot_test_labels).item()\n",
        "\n",
        "                # Compute validation accuracy for this batch\n",
        "                test_probs = nn.Softmax(dim=1)(test_logits)\n",
        "                test_predicted = torch.argmax(test_probs, dim=1)\n",
        "                total_test_samples += test_labels.size(0)\n",
        "                test_correct_predictions += (test_predicted == test_labels).sum().item()\n",
        "\n",
        "        # Calculate average validation loss for the epoch\n",
        "        avg_test_loss = test_loss / len(self.test_loader)\n",
        "\n",
        "        # Calculate validation accuracy for the epoch\n",
        "        avg_test_accuracy = test_correct_predictions / total_test_samples\n",
        "\n",
        "        conf_matrix, prettified_f1_scores, prettified_precision_scores, prettified_recall_scores = self.get_metrics_for_class_predictions(\n",
        "            predicted_labels, true_labels\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"test_loss\": avg_test_loss,\n",
        "            \"test_accuracy\": avg_test_accuracy,\n",
        "            \"conf_matrix\": conf_matrix,\n",
        "            \"f1_scores\": prettified_f1_scores,\n",
        "            \"recall_scores\": prettified_recall_scores,\n",
        "            \"precision_scores\": prettified_precision_scores\n",
        "        }\n",
        "\n",
        "    def get_metrics_for_class_predictions(self, predicted_labels, true_labels):\n",
        "        # Calculate the confusion matrix\n",
        "        conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "        # Calculate F1 score, recall, and precision for each class\n",
        "        f1_scores = f1_score(true_labels, predicted_labels, average=None)\n",
        "        recall_scores = recall_score(true_labels, predicted_labels, average=None)\n",
        "        precision_scores = precision_score(true_labels, predicted_labels, average=None)\n",
        "        # Create dictionaries with prettified class labels\n",
        "        prettified_f1_scores = {self.class_names[i]: f1_scores[i] for i in range(len(self.class_names))}\n",
        "        prettified_recall_scores = {self.class_names[i]: recall_scores[i] for i in range(len(self.class_names))}\n",
        "        prettified_precision_scores = {self.class_names[i]: precision_scores[i] for i in range(len(self.class_names))}\n",
        "        # Print the confusion matrix with class labels\n",
        "        self.print_confusion_matrix(conf_matrix)\n",
        "        return conf_matrix, prettified_f1_scores, prettified_precision_scores, prettified_recall_scores\n",
        "\n",
        "    def print_confusion_matrix(self, conf_matrix):\n",
        "        print(\"Confusion Matrix\")\n",
        "        cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=self.class_names)\n",
        "        cm_display.plot()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "DR717Dx-v5wO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All Previous Models\n"
      ],
      "metadata": {
        "id": "kVuzcPGW0fhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WBC Base Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "R4FPDD8hcCf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WBCClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = self.conv_and_batch_norm_block(3, 64, pool=True)\n",
        "        self.conv2 = self.conv_and_batch_norm_block(64, 64, pool=True)\n",
        "        self.res1 = self.conv_and_batch_norm_block(64, 64)\n",
        "        self.res2 = self.conv_and_batch_norm_block(64, 64)\n",
        "\n",
        "        self.conv3 = self.conv_and_batch_norm_block(64, 32, pool=True)\n",
        "        self.conv4 = self.conv_and_batch_norm_block(32, 16, pool=True)\n",
        "        self.res3 = self.conv_and_batch_norm_block(16, 16)\n",
        "        self.res4 = self.conv_and_batch_norm_block(16, 16)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            #Input shape is (b, 16,16,16)\n",
        "            # Convolutional layers to reduce spatial dimensions\n",
        "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1),  # Shape: (b, 8, 16, 16)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Shape: (b, 8, 8, 8)\n",
        "\n",
        "            nn.Flatten(),  # Shape: (b, 64 * 4 * 4)\n",
        "\n",
        "            # Linear layers with ReLU activation\n",
        "            nn.Linear(8 * 8 * 8, 64),  # Shape: (b, 64)\n",
        "            nn.ReLU(),  # Shape: (b, 64)\n",
        "\n",
        "            nn.Linear(64, 8),  # Shape: (b, 32)\n",
        "            nn.ReLU(),  # Shape: (b, 32)\n",
        "\n",
        "            nn.Linear(8, self.num_classes)  # Final linear layer with output size 5 (for 5 classes)\n",
        "        ).to(config.device)\n",
        "\n",
        "    def conv_and_batch_norm_block(self, in_channels, out_channels, pool=False):\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        if pool:\n",
        "            layers.append(nn.MaxPool2d(2))\n",
        "        return nn.Sequential(*layers).to(config.device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)  # shape (b,64,128,128)\n",
        "        out1 = self.conv2(out)  # shape (b,64,64,64)\n",
        "        out = self.res1(out1) + out1  # skip connections, shape (b,64,64,64)\n",
        "        out = out1 + self.res2(out) + out  # multi skip connections, shape (b,64,64,64)\n",
        "\n",
        "        out = self.conv3(out)  # shape is (b,32,32,32)\n",
        "        out2 = self.conv4(out)  # shape is (b,16,16,16)\n",
        "        out = self.res3(out2) + out2  # skip connections, shape is (b,16,16,16)\n",
        "        out = out2 + self.res4(out) + out  # multi skip connections, shape is (b,16,16,16)\n",
        "\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "3lKe9B6i0hDR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pRCC autoencoder model\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "PEACHeWdcCf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "outputs": [],
      "source": [
        "class pRCCAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1).to(config.device)\n",
        "        self.encoder_conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1).to(config.device)\n",
        "        self.encoder_conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1).to(config.device)\n",
        "        # self.encoder_conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1).to(config.device)\n",
        "        # self.encoder_conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1).to(config.device)\n",
        "        # self.encoder_conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1).to(config.device)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder_conv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2).to(config.device)\n",
        "        self.decoder_conv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2).to(config.device)\n",
        "        self.decoder_conv1 = nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2).to(config.device)\n",
        "\n",
        "        #Maxpool\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2).to(config.device)\n",
        "\n",
        "        #Batch norms\n",
        "        self.bn3 = nn.BatchNorm2d(3).to(config.device)\n",
        "        self.bn32 = nn.BatchNorm2d(32).to(config.device)\n",
        "        self.bn64 = nn.BatchNorm2d(64).to(config.device)\n",
        "        self.bn128 = nn.BatchNorm2d(128).to(config.device)\n",
        "        self.bn256 = nn.BatchNorm2d(256).to(config.device)\n",
        "\n",
        "        #Activation\n",
        "        self.relu = nn.ReLU().to(config.device)\n",
        "        self.sigmoid = nn.Sigmoid().to(config.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoding\n",
        "        x1_enc = self.encoder_conv1(x)# Shape: (batch_size, 32, 512, 512)\n",
        "        # x1_enc = self.bn32(x1_enc)\n",
        "        x1_enc = self.relu(x1_enc)\n",
        "        x1_enc = self.maxpool(x1_enc) #Shape: (b, 32,256,256)\n",
        "\n",
        "        x2_enc = self.encoder_conv2(x1_enc)  # Shape: (batch_size, 64, 256, 256)\n",
        "        # x2_enc = self.bn64(x2_enc)\n",
        "        x2_enc = self.relu(x2_enc)\n",
        "        x2_enc = self.maxpool(x2_enc) # Shape: (batch_size, 64, 128, 128)\n",
        "\n",
        "        x3_enc = self.encoder_conv3(x2_enc)  # Shape: (batch_size, 128, 128, 128)\n",
        "        # x3_enc = self.bn128(x3_enc)\n",
        "        x3_enc = self.relu(x3_enc)\n",
        "        x3_enc = self.maxpool(x3_enc) # Shape: (batch_size, 128, 64, 64)\n",
        "\n",
        "\n",
        "        # Decoding\n",
        "        x3_dec = self.decoder_conv3(x3_enc)  # Shape: (batch_size, 64, 128, 128)\n",
        "        # x5_dec = self.bn256(x5_dec)\n",
        "        x3_dec = self.relu(x3_dec)\n",
        "\n",
        "        x2_dec = self.decoder_conv2(x3_dec)  # Shape: (batch_size, 32, 256, 256)\n",
        "        # x4_dec = self.bn128(x4_dec)\n",
        "        x2_dec = self.relu(x2_dec)\n",
        "\n",
        "        x1_dec = self.decoder_conv1(x2_dec)  # Shape: (batch_size, 3, 512, 512)\n",
        "        # x1_dec = self.bn3(x1_dec)\n",
        "        x1_dec = self.sigmoid(x1_dec)\n",
        "\n",
        "        return x3_enc, x1_dec"
      ],
      "metadata": {
        "id": "oSwKtDQUcCf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Camelyon 16 classifier model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ScKM2giHcCf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "outputs": [],
      "source": [
        "class CamelyonClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = self.conv_and_batch_norm_block(3, 64)\n",
        "        self.conv2 = self.conv_and_batch_norm_block(64, 128, pool=True)\n",
        "        self.res1 = self.conv_and_batch_norm_block(128, 128)\n",
        "        self.res2 = self.conv_and_batch_norm_block(128, 128)\n",
        "\n",
        "        self.conv3 = self.conv_and_batch_norm_block(128, 256, pool=True)\n",
        "        self.conv4 = self.conv_and_batch_norm_block(256, 512, pool=True)\n",
        "\n",
        "        self.res3 = self.conv_and_batch_norm_block(512, 512)\n",
        "        self.res4 = self.conv_and_batch_norm_block(512, 512)\n",
        "\n",
        "        self.linear_stack = nn.Sequential(\n",
        "            nn.MaxPool2d(4),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32768, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(32, 5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Replace the initial layers with a pre-trained ResNet-18 backbone\n",
        "        self.resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "        #set to non trainable\n",
        "        self.resnet18.eval()\n",
        "        for param in self.resnet18.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        #remove the fully connected layer\n",
        "        self.resnet18.fc = nn.Identity()  # Remove the fully connected layer (classifier)\n",
        "\n",
        "        self.resnet_linear_stack = nn.Sequential(\n",
        "            nn.Linear(512, 128),  # Adjust input size based on the output of ResNet-18\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),  # Adjust input size based on the output of ResNet-18\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),  # Adjust input size based on the output of ResNet-18\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 32),  # Adjust input size based on the output of ResNet-18\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 5),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(5, self.num_classes)\n",
        "        )\n",
        "\n",
        "    def conv_and_batch_norm_block(self, in_channels, out_channels, pool=False):\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        if pool:\n",
        "            layers.append(nn.MaxPool2d(2))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # Pass input through the ResNet-18 backbone\n",
        "        features = self.resnet18(x)\n",
        "\n",
        "        # Continue with the linear stack and predictor\n",
        "        linear_stack = self.resnet_linear_stack(features)\n",
        "        predictor = self.predictor(linear_stack)\n",
        "        return linear_stack, predictor\n",
        "\n",
        "    def old_forward(self, x):\n",
        "        '''\n",
        "        This contains the old model architecture\n",
        "\n",
        "        :param x:\n",
        "        :return:\n",
        "        '''\n",
        "        #Assumes that x is of shape (b, 3, 256,256)\n",
        "        out = self.conv1(x)  # shape (b,64,256,256)\n",
        "        out1 = self.conv2(out)  # shape (b,128,128,128)\n",
        "        out = self.res1(out1) + out1  # skip connections, shape (b,128,128,128)\n",
        "\n",
        "        out = out1 + self.res2(out) + out  # multi skip connections, shape (b,128,128,128)\n",
        "        out = self.conv3(out)  # shape is (b,256,64,64)\n",
        "        out2 = self.conv4(out)  # shape is (b,512,32,32)\n",
        "\n",
        "        out = self.res3(out2) + out2  # skip connections, shape is (b,512,32,32)\n",
        "        out = out2 + self.res4(out) + out  # multi skip connections, shape is (b,512,32,32)\n",
        "\n",
        "        linear_stack = self.linear_stack(out)\n",
        "        predictor = self.predictor(linear_stack)\n",
        "        return linear_stack, predictor"
      ],
      "metadata": {
        "id": "Qh_0CESlcCf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "bFYa8C-OcCf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "outputs": [],
      "source": [
        "class PretrainedWBCClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 pRCC_model,\n",
        "                 Cam16_model,\n",
        "                 WBC_model,\n",
        "                 pRCC_weights_path=None,\n",
        "                 cam_weights_path=None,\n",
        "                 wbc_weights_path=None\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pRCC_model = pRCC_model.to(config.device)\n",
        "        self.Cam16_model = Cam16_model.to(config.device)\n",
        "        self.WBC_model = WBC_model.to(config.device)\n",
        "\n",
        "        if pRCC_weights_path:\n",
        "            print(f\"Loading the pRCC weights from {pRCC_weights_path}\")\n",
        "            pRCC_checkpoint = torch.load(pRCC_weights_path, map_location=config.device)\n",
        "            print(f\"Retrieved the pRCC Checkpoint file!\")\n",
        "            print(f\"Keys present in this checkpoint are {pRCC_checkpoint.keys()}\")\n",
        "            # Load the best weights for the pRCC model and make it non-trainable\n",
        "            self.pRCC_model.load_state_dict(pRCC_checkpoint['model_state_dict'])\n",
        "            print(f\"Finished loading the pRCC weights from {pRCC_weights_path}\")\n",
        "            self.pRCC_model.eval()\n",
        "            for param in self.pRCC_model.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(f\"Setting the pRCC model to eval mode and non trainable!\")\n",
        "\n",
        "        if cam_weights_path:\n",
        "            print(f\"Loading the Camelyon weights from {cam_weights_path}\")\n",
        "            # Load the best weights for the Cam16 model and make it non-trainable\n",
        "            cam_checkpoint = torch.load(cam_weights_path, map_location=config.device)\n",
        "            print(f\"Retrieved the Camelyon Checkpoint file!\")\n",
        "            print(f\"Keys present in this checkpoint are {cam_checkpoint.keys()}\")\n",
        "            self.Cam16_model.load_state_dict(cam_checkpoint['model_state_dict'])\n",
        "            print(f\"Finished loading the Camelyon weights from {cam_weights_path}\")\n",
        "            self.Cam16_model.eval()\n",
        "            for param in self.Cam16_model.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(f\"Setting the Camelyon model to eval mode and non trainable!\")\n",
        "\n",
        "        if wbc_weights_path:\n",
        "            print(f\"Loading the base WBC weights from {wbc_weights_path}\")\n",
        "            # Load the best weights for the WBC model (which remains trainable)\n",
        "            wbc_checkpoint = torch.load(wbc_weights_path, map_location=config.device)\n",
        "            print(f\"Retrieved the WBC Checkpoint file!\")\n",
        "            print(f\"Keys present in this checkpoint are {wbc_checkpoint.keys()}\")\n",
        "            self.WBC_model.load_state_dict(wbc_checkpoint)\n",
        "            print(f\"Finished loading the base WBC weights from {wbc_weights_path}\")\n",
        "\n",
        "        #Input (batch_size, 128, 64, 64)\n",
        "        self.pRCC_latent_to_output = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  # Output shape: (batch_size, 256, 64, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (batch_size, 256, 32, 32)\n",
        "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),  # Output shape: (batch_size, 128, 32, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (batch_size, 128, 16, 16)\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),  # Output shape: (batch_size, 64, 16, 16)\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (batch_size, 64, 8, 8)\n",
        "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),  # Output shape: (batch_size, 32, 8, 8)\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (batch_size, 32, 4, 4)\n",
        "            nn.Flatten(),  # Output shape: (batch_size, 32 * 4 * 4)\n",
        "            nn.Linear(32 * 4 * 4, 5)  # Output shape: (batch_size, 5)\n",
        "        ).to(config.device)\n",
        "\n",
        "        # Additional linear layer to combine the outputs of all three models (5 + 5 + 5)\n",
        "        self.combine_outputs = nn.Linear(5, 5).to(config.device)\n",
        "\n",
        "    def forward(self, pRCC_input, Cam16_input, WBC_input):\n",
        "        # Forward pass through pRCC model\n",
        "        pRCC_latent, _ = self.pRCC_model(pRCC_input)\n",
        "        pRCC_output = self.pRCC_latent_to_output(pRCC_latent)\n",
        "\n",
        "        # Forward pass through Cam16 model ( the second one is the prediction across 2 classes)\n",
        "        Cam16_output, _ = self.Cam16_model(Cam16_input)\n",
        "\n",
        "        # Forward pass through WBC model\n",
        "        WBC_output = self.WBC_model(WBC_input)\n",
        "\n",
        "        # Combine the outputs from each of the model\n",
        "        combined_output = pRCC_output + Cam16_output + WBC_output\n",
        "\n",
        "        # Combine the outputs of all three models\n",
        "        combined_predictor = self.combine_outputs(combined_output)\n",
        "\n",
        "        return combined_predictor"
      ],
      "metadata": {
        "id": "0dsDi8kLcCf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the dataset"
      ],
      "metadata": {
        "id": "pcKjb64uzaCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.abspath(config.datasets_path)\n",
        "eval_path = os.path.abspath(config.eval_path)\n",
        "pretrained_wbc_dataset = PretrainedWBCDataset(path, eval_path)"
      ],
      "metadata": {
        "id": "oaLHAg1dzbvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06825484-ccc4-432c-d8bf-a775dc57d91e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "constructing test & val dataset with augmentation\n",
            "constructing train dataset\n",
            "Datasets are initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training code"
      ],
      "metadata": {
        "id": "2hh145Fzv6dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# initialize other models\n",
        "pRCC_model = pRCCAutoencoder()\n",
        "cam_model = CamelyonClassifier()\n",
        "wbc_model = WBCClassifier()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5b_zWjZcCf-",
        "outputId": "50f154e9-f3c8-41bf-b5ef-1c05a5bc2ee5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "outputs": [],
      "source": [
        "# get the paths of the best saved models\n",
        "pRCC_weights_path = os.path.join(config.weights_path, \"pRCC_Autoencoder\", \"model_epoch_20.pt\")\n",
        "cam_weights_path = os.path.join(config.weights_path, \"camelyon_classifier\", \"model_epoch_52.pt\")\n",
        "wbc_weights_path = os.path.join(config.weights_path, \"wbc_100_base\", \"model_epoch_10.pt\")"
      ],
      "metadata": {
        "id": "HuRJar0KcCf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"wbc_100_pretrained\"\n",
        "pretrained_model = PretrainedWBCClassifier(\n",
        "    pRCC_model = pRCC_model,\n",
        "    Cam16_model = cam_model,\n",
        "    WBC_model = wbc_model,\n",
        "    pRCC_weights_path=pRCC_weights_path,\n",
        "    cam_weights_path=cam_weights_path,\n",
        "    wbc_weights_path=None\n",
        "    # wbc_weights_path=wbc_weights_path #If at all we want to take the already best saved model\n",
        ").to(config.device)\n",
        "save_dir = os.path.abspath(config.weights_path)\n",
        "pretrained_wbc_trainer = PretrainedWBCClassifierTrainer(name, pretrained_wbc_dataset, pretrained_model, save_dir)"
      ],
      "metadata": {
        "id": "6cBbSwi4v7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d368960-8099-4fdf-a3ff-1574166caabf"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the pRCC weights from /content/drive/MyDrive/weights/pRCC_Autoencoder/model_epoch_20.pt\n",
            "Retrieved the pRCC Checkpoint file!\n",
            "Keys present in this checkpoint are dict_keys(['model_state_dict', 'optimizer_state_dict', 'epoch', 'epoch_numbers', 'training_losses', 'validation_losses'])\n",
            "Finished loading the pRCC weights from /content/drive/MyDrive/weights/pRCC_Autoencoder/model_epoch_20.pt\n",
            "Setting the pRCC model to eval mode and non trainable!\n",
            "Loading the Camelyon weights from /content/drive/MyDrive/weights/camelyon_classifier/model_epoch_52.pt\n",
            "Retrieved the Camelyon Checkpoint file!\n",
            "Keys present in this checkpoint are dict_keys(['model_state_dict', 'optimizer_state_dict', 'epoch', 'epoch_numbers', 'training_losses', 'training_accuracies', 'validation_losses', 'validation_accuracies'])\n",
            "Finished loading the Camelyon weights from /content/drive/MyDrive/weights/camelyon_classifier/model_epoch_52.pt\n",
            "Setting the Camelyon model to eval mode and non trainable!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_numbers, training_losses, training_accuracies, validation_losses, validation_accuracies = pretrained_wbc_trainer.train(14, epoch_saver_count=1)"
      ],
      "metadata": {
        "id": "Mq6FCVms5-a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training for more epochs if required"
      ],
      "metadata": {
        "collapsed": false,
        "id": "yM4RFtuDpyNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch_numbers, training_losses, training_accuracies, validation_losses, validation_accuracies = pretrained_wbc_trainer.train(10, epoch_saver_count=2, load_from_checkpoint=True, resume_epoch_num=42)"
      ],
      "metadata": {
        "id": "ytytzkge0bhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "3sieNJtl1egT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_stats = pretrained_wbc_trainer.test_model()"
      ],
      "metadata": {
        "id": "JPtZU1Jv1DJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Loss: {test_stats['test_loss']} | Test Accuracy: {test_stats['test_accuracy']}\")"
      ],
      "metadata": {
        "id": "45Pk85jC1h0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_stats['conf_matrix']"
      ],
      "metadata": {
        "id": "Pdzpr00Gy-0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_wbc_trainer.print_confusion_matrix(test_stats['conf_matrix'])"
      ],
      "metadata": {
        "id": "A7kWzogqwd4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1 scores\")\n",
        "test_stats['f1_scores']"
      ],
      "metadata": {
        "id": "4ExlkX8SwE1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision scores\")\n",
        "test_stats['precision_scores']"
      ],
      "metadata": {
        "id": "aLUhaaGRwIp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recall scores\")\n",
        "test_stats['recall_scores']"
      ],
      "metadata": {
        "id": "tARa89SSv8XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the graphs"
      ],
      "metadata": {
        "id": "4-gWibEs1nIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_stats(name, epoch_numbers, training_losses, validation_losses, training_accuracies, validation_accuracies)"
      ],
      "metadata": {
        "id": "ksgSnkZi1i1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtFPE9rAEuG3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}